{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 試験ドットコム系\n",
    "\n",
    "Websites:\n",
    "\n",
    "- https://www.sc-siken.com/\n",
    "- https://www.ap-siken.com/\n",
    "- https://denkou2-siken.com/\n",
    "- https://www.db-siken.com/\n",
    "- https://www.pm-siken.com/\n",
    "- https://www.nw-siken.com/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install html5lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SITES = [\n",
    "    \"https://www.sc-siken.com\",\n",
    "    \"https://www.ap-siken.com\",\n",
    "    \"https://denkou2-siken.com\",\n",
    "    \"https://www.db-siken.com\",\n",
    "    \"https://www.pm-siken.com\",\n",
    "    \"https://www.nw-siken.com\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get past exams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_pages: list[BeautifulSoup] = []\n",
    "\n",
    "client = requests.Session()\n",
    "\n",
    "for url in TARGET_SITES:\n",
    "    res = client.get(url)\n",
    "    if res.status_code != 200:\n",
    "        raise Exception(f\"{url} got {res.status_code}!!\")\n",
    "\n",
    "    res.encoding = res.apparent_encoding\n",
    "\n",
    "    top_pages.append(BeautifulSoup(res.content, \"lxml\"))\n",
    "\n",
    "top_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_exam_urls: list[dict[str, str]] = []\n",
    "\n",
    "for url, page in zip(TARGET_SITES, top_pages):\n",
    "    link_els = page.select(\"ul#testMenu > li > a\")\n",
    "    if len(link_els) == 0:\n",
    "        link_els = page.select(\"el#test_menu > li > a\")\n",
    "\n",
    "    urls = [\n",
    "        {\n",
    "            \"base_url\": url,\n",
    "            \"url\": f\"{url}{el.get('href')}\",\n",
    "        }\n",
    "        for el in link_els\n",
    "    ]\n",
    "\n",
    "    past_exam_urls.extend(urls)\n",
    "\n",
    "past_exam_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(past_exam_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache HTMLs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_exam_pages: list[dict] = []\n",
    "\n",
    "client = requests.Session()\n",
    "\n",
    "for url_data in tqdm(past_exam_urls):\n",
    "    res = client.get(url_data[\"url\"])\n",
    "    if res.status_code != 200:\n",
    "        raise Exception(f\"{url} got {res.status_code}!!\")\n",
    "\n",
    "    res.encoding = res.apparent_encoding\n",
    "\n",
    "    # lxml はエラー\n",
    "    past_exam_pages.append(\n",
    "        {\n",
    "            \"base_url\": url_data[\"base_url\"],\n",
    "            \"url\": url_data[\"url\"],\n",
    "            # html が不正なので html5lib を使う\n",
    "            \"soup\": BeautifulSoup(res.content, \"html5lib\"),\n",
    "        }\n",
    "    )\n",
    "\n",
    "past_exam_pages[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse HTML and get questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [00:00<00:00, 79.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2271"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collected_questions = set()\n",
    "\n",
    "questions_data = []\n",
    "\n",
    "\n",
    "def get_questions(base_url: str, url: str, soup: BeautifulSoup):\n",
    "    qtables = soup.select(\"table.qtable\")\n",
    "    assert len(qtables) > 0, soup\n",
    "\n",
    "    tr_els = []\n",
    "    for qtable in qtables:\n",
    "        if qtable.select_one(\"tbody\") is not None:\n",
    "            tr_els.extend(qtable.select(\"tbody > tr\"))\n",
    "        else:\n",
    "            tr_els.extend(qtable.select(\"tr\"))\n",
    "\n",
    "    for tr in tr_els:\n",
    "        if tr.select_one(\"th\") is not None:\n",
    "            # 見出しはスキップ\n",
    "            continue\n",
    "\n",
    "        is_ok_explanation = tr.select_one(\"i.ok\") is not None\n",
    "        # 解説なければスキップ\n",
    "        if not is_ok_explanation:\n",
    "            continue\n",
    "\n",
    "        td_els = tr.select(\"td\")\n",
    "        link = td_els[0].select_one(\"a\").get(\"href\")\n",
    "        title = td_els[1].text\n",
    "        category = td_els[2].text\n",
    "\n",
    "        # 収集済みならスキップ\n",
    "        if f\"{category}.{title}\" in collected_questions:\n",
    "            continue\n",
    "\n",
    "        questions_data.append(\n",
    "            {\n",
    "                \"base_url\": base_url,\n",
    "                \"url\": url + link,\n",
    "                \"title\": title,\n",
    "                \"category\": category,\n",
    "            }\n",
    "        )\n",
    "        collected_questions.add(f\"{category}.{title}\")\n",
    "\n",
    "\n",
    "for page in tqdm(past_exam_pages):\n",
    "    get_questions(page[\"base_url\"], page[\"url\"], page[\"soup\"])\n",
    "\n",
    "len(questions_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'base_url': 'https://www.ap-siken.com',\n",
       "  'url': 'https://www.ap-siken.com/kakomon/05_aki/q1.html',\n",
       "  'title': '2進数2けたを表す式',\n",
       "  'category': '応用数学'},\n",
       " {'base_url': 'https://www.ap-siken.com',\n",
       "  'url': 'https://www.ap-siken.com/kakomon/05_aki/q2.html',\n",
       "  'title': '主成分分析',\n",
       "  'category': '応用数学'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache HTMLs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2271it [08:42,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "client = requests.Session()\n",
    "\n",
    "for i, data in tqdm(enumerate(questions_data)):\n",
    "    res = client.get(data[\"url\"])\n",
    "\n",
    "    if res.status_code != 200:\n",
    "        raise Exception(f\"{url} got {res.status_code}!!\")\n",
    "\n",
    "    res.encoding = res.apparent_encoding\n",
    "\n",
    "    # html が不正なので html5lib を使う\n",
    "    soup = BeautifulSoup(res.content, \"html5lib\")\n",
    "\n",
    "    questions_data[i][\"html\"] = soup\n",
    "\n",
    "    time.sleep(0.1)  # avoid 429\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get QA details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_char_map = {\n",
    "    \"ア\": 0,\n",
    "    \"イ\": 1,\n",
    "    \"ウ\": 2,\n",
    "    \"エ\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2271/2271 [00:08<00:00, 265.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1879"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_question_details(soup: BeautifulSoup):\n",
    "    # 午後問題かも\n",
    "    if soup.select_one(\"a#splitWindowBtn\") is not None:\n",
    "        return None\n",
    "\n",
    "    question: dict = {\n",
    "        \"question_body\": None,\n",
    "        \"choice_0\": None,\n",
    "        \"choice_1\": None,\n",
    "        \"choice_2\": None,\n",
    "        \"choice_3\": None,\n",
    "        # \"answer_char\": None,\n",
    "        \"answer_num\": None,\n",
    "        \"explanation\": None,\n",
    "        \"explanation_choice_0\": None,\n",
    "        \"explanation_choice_1\": None,\n",
    "        \"explanation_choice_2\": None,\n",
    "        \"explanation_choice_3\": None,\n",
    "    }\n",
    "\n",
    "    mondai = soup.select_one(\"section#mondai\")\n",
    "    if mondai is None:\n",
    "        mondai = soup.select_one(\"div#mondai\")\n",
    "    if mondai is None:\n",
    "        mondai = soup.select_one(\"article#mondai\")\n",
    "    assert mondai is not None, soup\n",
    "\n",
    "    mondai_text = mondai.text\n",
    "    question[\"question_body\"] = mondai_text\n",
    "\n",
    "    choices = soup.select(\"div.ansbg > ul > li > span\")\n",
    "    if len(choices) == 0:\n",
    "        return None\n",
    "\n",
    "    for i, choice in enumerate(choices):\n",
    "        question[f\"choice_{i}\"] = choice.text\n",
    "\n",
    "    answer_char_el = soup.select_one(\"span#answerChar\")\n",
    "    assert answer_char_el is not None\n",
    "\n",
    "    answer_char = answer_char_el.text\n",
    "    answer_num = answer_char_map[answer_char_el.text]\n",
    "\n",
    "    # question[\"answer_char\"] = answer_char\n",
    "    question[\"answer_num\"] = answer_num\n",
    "\n",
    "    kaisetsu = soup.select_one(\"div#kaisetsu\")\n",
    "    assert kaisetsu is not None\n",
    "\n",
    "    if kaisetsu.select_one(\"ul > li.lia\") is not None:\n",
    "        kaisetsu_choice_els = kaisetsu.select(\"ul > li\")\n",
    "        assert len(kaisetsu_choice_els) > 0\n",
    "\n",
    "        for i, el in enumerate(kaisetsu_choice_els):\n",
    "            question[f\"explanation_choice_{i}\"] = el.text\n",
    "            el.decompose()\n",
    "\n",
    "    question[\"explanation\"] = kaisetsu.text\n",
    "\n",
    "    return question\n",
    "\n",
    "    # print(kaisetsu.text)\n",
    "\n",
    "\n",
    "all_questions = []\n",
    "\n",
    "for data in tqdm(questions_data):\n",
    "    # print(data[\"url\"])\n",
    "    question = get_question_details(data[\"html\"])\n",
    "    if question is None:\n",
    "        continue\n",
    "    question[\"base_url\"] = data[\"base_url\"]\n",
    "    question[\"url\"] = data[\"url\"]\n",
    "    all_questions.append(question)\n",
    "\n",
    "len(all_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question_body': '2けたの2進数x1x2が表す整数をxとする。2進数x2x1が表す整数を，xの式で表したものはどれか。ここで，int(r)は非負の実数rの小数点以下を切り捨てた整数を表す。',\n",
       "  'choice_0': '2x＋4int(x2)',\n",
       "  'choice_1': '2x＋5int(x2)',\n",
       "  'choice_2': '2x−3int(x2)',\n",
       "  'choice_3': '2x−4int(x2)',\n",
       "  'answer_num': 2,\n",
       "  'explanation': 'x(エックス)と×(かける)が紛らわしいので、解説中では乗算の演算子を * としています。整数xは10進数で x1*2 + x2 なので、選択肢中の2xは10進数で以下のように示すことができます。\\u30002x = x1*4 + x2*2\\u3000…①次に、選択肢中の int(x2) について考えます。x2は、xを右に1ビットシフト（12）させたものなので、\\u3000x1x2→(右へ1ビットシフト)→x1.x2 （\".\"は小数点）さらに、int()は整数部を取り出す操作なので、\\u3000int(x1.x2) = x1つまり、int(x2) は x1 と同じ値ということになります。\\u3000int(x2) = x1\\u3000…②①と同様に、2進数x2x1を10進数で表すと x2*2 + x1 です。これを先程の①と比べると、両者の差分は x1 が3つ分となっています。\\u3000x1*4 + x2*2 - x1*3 = x2*2 + x1\\u3000…③①②より 2x = x1*4＋x2*2、x1 = int(x2) なので、③の左辺の該当部分を置き換えると、以下のように表すことができます。\\u30002x−3int(x2)＝x2*2＋x1したがって「ウ」の式が適切です。【別解】ここまでがこの設問の正しい理解ですが、実際の試験本番では x1＝1，x2＝1 として、\\u3000x1x2＝11(2)＝3(10)\\u3000x2x1＝11(2)＝3(10)\\u3000int(x2)＝1\\u30003＝2*3−a\\u3000a＝3で「ウ」が正解としたり、x1＝1，x2＝0 として、\\u3000x1x2＝10(2)＝2(10)\\u3000x2x1＝01(2)＝1(10)\\u3000int(x／2)＝1\\u30001＝2*2−a\\u3000a＝3とするなど、簡単に計算できる値を代入して消去法で解く方法が無難でしょう。',\n",
       "  'explanation_choice_0': None,\n",
       "  'explanation_choice_1': None,\n",
       "  'explanation_choice_2': None,\n",
       "  'explanation_choice_3': None,\n",
       "  'base_url': 'https://www.ap-siken.com',\n",
       "  'url': 'https://www.ap-siken.com/kakomon/05_aki/q1.html'},\n",
       " {'question_body': '複数の変数をもつデータに対する分析手法の記述のうち，主成分分析はどれか。',\n",
       "  'choice_0': '変数に共通して影響を与える新たな変数を計算して，データの背後にある構造を取得する方法',\n",
       "  'choice_1': '変数の値からほかの変数の値を予測して，データがもつ変数間の関連性を確認する方法',\n",
       "  'choice_2': '変数の値が互いに類似するものを集めることによって，データを分類する方法',\n",
       "  'choice_3': '変数を統合した新たな変数を使用して，データがもつ変数の数を減らす方法',\n",
       "  'answer_num': 3,\n",
       "  'explanation': '主成分分析は、複数の要因が相互に関連している場合に、その群の特性を決定づけている主な要因を合成変数として求める統計的な手法です。合成された変数を主成分と呼びます。情報の損失を最小限に抑えながら変数を減らすことで、分析対象のデータを理解しやすくする効果があります。国数理社英の5教科の得点から総合評価点を求める、身長と体重をBMIという1つの指標にする、アンケート調査の分析で寄与度が高い要素を抽出するなどが主成分分析の例です。したがって「エ」が正解です。',\n",
       "  'explanation_choice_0': '因子分析の説明です。',\n",
       "  'explanation_choice_1': '回帰分析の説明です。',\n",
       "  'explanation_choice_2': 'クラスタ分析の説明です。',\n",
       "  'explanation_choice_3': '正しい。主成分分析は、多変量データの次元削減やデータの特徴抽出に用いられる手法です。',\n",
       "  'base_url': 'https://www.ap-siken.com',\n",
       "  'url': 'https://www.ap-siken.com/kakomon/05_aki/q2.html'}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_questions[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question_body', 'choice_0', 'choice_1', 'choice_2', 'choice_3', 'answer_num', 'explanation', 'explanation_choice_0', 'explanation_choice_1', 'explanation_choice_2', 'explanation_choice_3', 'base_url', 'url'],\n",
       "    num_rows: 1879\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_questions_ds = Dataset.from_list(all_questions)\n",
    "all_questions_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push to huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "102b2a9dfb854b8596cd8c1658fc215e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10248221a8f4bee8f5a877bbd366474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_questions_ds.push_to_hub(\"siken-dot-com-20240117\", private=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
